{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmtSLEFK+aR084t9KL/3yf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anannayajannat/HybridQCNN-Model/blob/main/2Augprob.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip --quiet"
      ],
      "metadata": {
        "id": "X62qH15FjwF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane==0.21.0 tensorflow==2.12.0 --quiet\n",
        "!pip install -U tensorflow_datasets --quiet"
      ],
      "metadata": {
        "id": "QRmQrUdQqgXZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5 tensorflow==2.12.0  pennylane==0.21.0 --quiet\n",
        "\n",
        "!pip install tensorflow_datasets --quiet\n",
        "!pip install scikit-learn keras-tuner matplotlib --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ0dgghqjyy9",
        "outputId": "20ef340f-be46-4fcf-9829-a97e38fe1a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "orbax-checkpoint 0.11.21 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "keras-hub 0.21.1 requires keras>=3.5, but you have keras 2.12.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y autograd\n",
        "!pip install autograd==1.8.0 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP-YD8-TiIV1",
        "outputId": "0e574249-0e1c-492d-d43c-a932dc7c8519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: autograd 1.8.0\n",
            "Uninstalling autograd-1.8.0:\n",
            "  Successfully uninstalled autograd-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n"
      ],
      "metadata": {
        "id": "nwBKgZo5gW2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "from pennylane.qnn.tensorflow import KerasLayer\n",
        "from pennylane.templates import AmplitudeEmbedding, AngleEmbedding\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "7FX8NnmYkdYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 4   # Quantum circuit will use 4 qubits\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "#Define Quantum Circuit\n",
        "@qml.qnode(dev, interface=\"tf\")\n",
        "def quantum_circuit(inputs, weights):\n",
        "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    # Return expectation values directly â€” no TF ops here\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "\n",
        "#Wrap Quantum Circuit as Keras Layer\n",
        "weight_shapes = {\"weights\": (2, n_qubits)} #trainable parameters per layer\n",
        "\n",
        "quantum_layer = qml.qnn.KerasLayer(\n",
        "    quantum_circuit,\n",
        "    weight_shapes=weight_shapes,\n",
        "    output_dim=n_qubits\n",
        ")\n",
        "\n",
        "#Hybrid Model Architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Dense(n_qubits),  # Reduce to quantum input dim (4)\n",
        "    tf.keras.layers.Activation('tanh'),\n",
        "    quantum_layer,  #  Quantum block\n",
        "\n",
        "    # Add Lambda layer to cast output to float32\n",
        "    # & take real part (avoid complex warning)\n",
        "    tf.keras.layers.Lambda(lambda x: tf.cast(tf.math.real(x), tf.float32)),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "D31R4UCbNGWs",
        "outputId": "49ede85b-525d-4e02-bccb-cb9805268b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'pennylane.qnn' has no attribute 'KerasLayer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-875173383.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mweight_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#trainable parameters per layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m quantum_layer = qml.qnn.KerasLayer(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mquantum_circuit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mweight_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pennylane/qnn/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {__name__!r} has no attribute {name!r}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pennylane.qnn' has no attribute 'KerasLayer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUhHAwOAo6VC"
      },
      "outputs": [],
      "source": [
        "# Load Fashion MNIST dataset\n",
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "class_names = metadata.features['label'].names\n",
        "print(\"Class names:\", class_names)\n",
        "\n",
        "num_train_examples = metadata.splits['train'].num_examples\n",
        "num_test_examples = metadata.splits['test'].num_examples\n",
        "print(f\"Number of training examples: {num_train_examples}\")\n",
        "print(f\"Number of test examples:     {num_test_examples}\")\n",
        "\n",
        "\n",
        "def normalize(images, labels):\n",
        "    images = tf.cast(images, tf.float32) / 255.0\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.map(normalize).cache().repeat().shuffle(num_train_examples).batch(128)\n",
        "test_dataset = test_dataset.map(normalize).cache().batch(128)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Limit steps_per_epoch to 500 for faster training\n",
        "# model.fit(train_dataset, epochs=10, steps_per_epoch=num_train_examples/64)\n",
        "model.fit(train_dataset, epochs=10, steps_per_epoch=100)\n",
        "loss, acc = model.evaluate(test_dataset)\n",
        "print(f\"Restored model accuracy: {acc:.4f}\")\n",
        "new_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Dense(n_qubits),  # Reduce to quantum input dim (4)\n",
        "    tf.keras.layers.Activation('tanh'),  # Normalize values in [-1, 1]\n",
        "\n",
        "    # Remove this layer: tf.keras.layers.Lambda(lambda x: tf.cast(x, tf.float32)),\n",
        "\n",
        "    quantum_layer,  # <-- Quantum block\n",
        "\n",
        "    # Add Lambda layer to cast output to float32 and take real part (avoid complex warning)\n",
        "    tf.keras.layers.Lambda(lambda x: tf.cast(tf.math.real(x), tf.float32)),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "new_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# new_model.load_weights(\"abc.h5\")\n",
        "new_model.load_weights('hybrid_20_epochs.h5')\n",
        "loss, acc = new_model.evaluate(test_dataset)\n",
        "print(f\"Restored new model accuracy: {acc:.4f}\")\n",
        "new_model.fit(train_dataset, initial_epoch=20, epochs=25, steps_per_epoch=100)\n",
        "loss, acc = new_model.evaluate(test_dataset)\n",
        "print(f\"Restored new model accuracy: {acc:.4f}\")\n"
      ]
    }
  ]
}